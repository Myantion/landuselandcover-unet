import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, Model
import os
import cv2
import glob
import matplotlib.pyplot as plt
import re
from tqdm import tqdm  # å¼•å…¥è¿›åº¦æ¡åº“
from matplotlib.colors import ListedColormap, BoundaryNorm  # æ˜¾å¼å¯¼å…¥

# --- Matplotlib ä¸­æ–‡é…ç½® ---
# âš ï¸ ç¡®ä¿æ‚¨çš„ç³»ç»Ÿä¸­å®‰è£…äº† SimHei å­—ä½“æˆ–å…¶ä»–ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False
# ---------------------------

# --- 0. å…¨å±€é…ç½®ä¸æœ¬åœ°è·¯å¾„ (â€¼ï¸ è¯·ä¿®æ”¹ä¸ºæ‚¨çš„æœ¬åœ°è·¯å¾„) ---
IMG_HEIGHT = 512
IMG_WIDTH = 512
NUM_BANDS = 3
INPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, NUM_BANDS)
NUM_CHANGE_CLASSES = 4
BATCH_SIZE = 16  # æ€§èƒ½ä¼˜åŒ–ï¼šæ¯æ¬¡é€å…¥æ¨¡å‹çš„åˆ‡ç‰‡æ•°é‡

# ğŸš¨ æ›¿æ¢ä¸ºæ‚¨æœ¬åœ° SECOND_data æ–‡ä»¶å¤¹çš„ç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹è·¯å¾„
SECOND_DATA_ROOT = './hnresults'
# ğŸš¨ æ›¿æ¢ä¸ºæ‚¨æœ¬åœ°ä¿å­˜çš„æƒé‡æ–‡ä»¶è·¯å¾„
CD_WEIGHTS_PATH = 'best_cd_finetune_weights.h5'

IM1_DIR = os.path.join(SECOND_DATA_ROOT, 'im1')
IM2_DIR = os.path.join(SECOND_DATA_ROOT, 'im2')

# ç¡®ä¿ TensorFlow ä½¿ç”¨ CPU
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
print("âœ… TensorFlow å·²é…ç½®ä¸ºä½¿ç”¨ CPUã€‚")


# --- 1. æ¨¡å‹ç»“æ„é‡æ–°å®šä¹‰ (ä¿æŒä¸å˜) ---

def conv_block(input_tensor, num_filters, kernel_size=(3, 3), name_suffix=''):
    x = layers.Conv2D(num_filters, kernel_size, activation='relu', padding='same',
                      name=f'conv_{num_filters}_a{name_suffix}')(input_tensor)
    x = layers.BatchNormalization(name=f'bn_{num_filters}_a{name_suffix}')(x)
    x = layers.Conv2D(num_filters, kernel_size, activation='relu', padding='same',
                      name=f'conv_{num_filters}_b{name_suffix}')(x)
    x = layers.BatchNormalization(name=f'bn_{num_filters}_b{name_suffix}')(x)
    return x


def encoder_block(input_tensor, num_filters, name_prefix):
    x = conv_block(input_tensor, num_filters, name_suffix=f'_{name_prefix}')
    p = layers.MaxPooling2D((2, 2), name=f'pool_{num_filters}_{name_prefix}')(x)
    return x, p


def decoder_block(input_tensor, skip_tensor, num_filters):
    x = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)
    x = layers.concatenate([x, skip_tensor])
    x = conv_block(x, num_filters)
    return x


def build_pseudo_siamese_unet(input_shape, num_change_classes):
    input_t1 = layers.Input(input_shape, name='input_t1')
    input_t2 = layers.Input(input_shape, name='input_t2')

    c1_t1, p1_t1 = encoder_block(input_t1, 32, 't1')
    c2_t1, p2_t1 = encoder_block(p1_t1, 64, 't1')
    c3_t1, p3_t1 = encoder_block(p2_t1, 128, 't1')
    c4_t1, p4_t1 = encoder_block(p3_t1, 256, 't1')

    c1_t2, p1_t2 = encoder_block(input_t2, 32, 't2')
    c2_t2, p2_t2 = encoder_block(p1_t2, 64, 't2')
    c3_t2, p3_t2 = encoder_block(p2_t2, 128, 't2')
    c4_t2, p4_t2 = encoder_block(p3_t2, 256, 't2')

    b_t1 = conv_block(p4_t1, 512, name_suffix='_bottleneck_t1')
    b_t2 = conv_block(p4_t2, 512, name_suffix='_bottleneck_t2')

    bottleneck_diff = layers.Subtract(name='bottleneck_diff')([b_t1, b_t2])

    diff_c4 = layers.Subtract(name='skip_diff_c4')([c4_t1, c4_t2])
    diff_c3 = layers.Subtract(name='skip_diff_c3')([c3_t1, c3_t2])
    diff_c2 = layers.Subtract(name='skip_diff_c2')([c2_t1, c2_t2])
    diff_c1 = layers.Subtract(name='skip_diff_c1')([c1_t1, c1_t2])

    u4 = decoder_block(bottleneck_diff, diff_c4, 256)
    u3 = decoder_block(u4, diff_c3, 128)
    u2 = decoder_block(u3, diff_c2, 64)
    u1 = decoder_block(u2, diff_c1, 32)

    outputs = layers.Conv2D(num_change_classes, (1, 1), activation='softmax', name='change_output')(u1)
    model = Model(inputs=[input_t1, input_t2], outputs=outputs, name='Pseudo_Siamese_CD')
    return model


# --- 2. åŠ è½½æ¨¡å‹å’Œæƒé‡ (ä¿æŒä¸å˜) ---

def load_best_model():
    model = build_pseudo_siamese_unet(INPUT_SHAPE, NUM_CHANGE_CLASSES)

    if os.path.exists(CD_WEIGHTS_PATH):
        try:
            model.load_weights(CD_WEIGHTS_PATH)
            print(f"âœ… æˆåŠŸåŠ è½½æœ€ä½³å˜åŒ–æ£€æµ‹æƒé‡: {CD_WEIGHTS_PATH}")
            return model
        except Exception as e:
            print(f"âŒ é”™è¯¯ï¼šåŠ è½½æƒé‡å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æŸåæˆ–è·¯å¾„æ˜¯å¦æ­£ç¡®: {e}")
            return None
    else:
        print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°æƒé‡æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ CD_WEIGHTS_PATH æ˜¯å¦æ­£ç¡®: {CD_WEIGHTS_PATH}")
        return None


# --- 3. è¾…åŠ©å‡½æ•°ï¼šåŠ è½½å’Œé¢„å¤„ç†åˆ‡ç‰‡ (ä¿æŒä¸å˜) ---

def load_and_preprocess_tile(im1_path, im2_path):
    # è¯»å– T1/T2 å›¾åƒå¹¶å½’ä¸€åŒ– (BGR -> RGB, 0-255 -> 0.0-1.0)
    im1 = cv2.cvtColor(cv2.imread(im1_path, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0
    im2 = cv2.cvtColor(cv2.imread(im2_path, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0

    return im1, im2


# --- 4. é¢„æµ‹å’Œæ‹¼æ¥å®Œæ•´å½±åƒå‡½æ•° (ä¿®å¤æ¥ç¼é—®é¢˜) ---

# å®šä¹‰è£å‰ªçš„åƒç´ æ•°ã€‚æˆ‘ä»¬å°†ä»é¢„æµ‹ç»“æœçš„æ¯ä¸ªè¾¹ç•Œè£å‰ªæ‰ CROP åƒç´ ã€‚
CROP_PIXELS = 1
TILE_EFFECTIVE_SIZE = IMG_HEIGHT - 2 * CROP_PIXELS  # 512 - 2*1 = 510


def predict_and_stitch_full_image(model):
    all_files_t1 = glob.glob(os.path.join(IM1_DIR, 'tile_*.png'))

    if not all_files_t1:
        print(f"âŒ é”™è¯¯ï¼šåœ¨ {IM1_DIR} ä¸­æœªæ‰¾åˆ°ä»»ä½• .png å›¾åƒåˆ‡ç‰‡ã€‚")
        return

    # 1. ç¡®å®šåŸå§‹å½±åƒçš„å°ºå¯¸ (è¡Œæ•°å’Œåˆ—æ•°) å’Œæ–‡ä»¶æ˜ å°„
    max_row, max_col = 0, 0
    file_metadata = []

    for path_t1 in all_files_t1:
        file_id = os.path.basename(path_t1)
        match = re.search(r'tile_(\d+)_(\d+)\.png', file_id)
        if match:
            row_idx = int(match.group(1))
            col_idx = int(match.group(2))

            max_row = max(max_row, row_idx)
            max_col = max(max_col, col_idx)

            file_metadata.append({'r': row_idx, 'c': col_idx, 'id': file_id})

    total_tiles = len(file_metadata)

    # æ ¹æ®è£å‰ªåçš„æœ‰æ•ˆå°ºå¯¸è®¡ç®—æœ€ç»ˆå›¾åƒå¤§å°
    new_total_rows = (max_row + 1) * TILE_EFFECTIVE_SIZE
    new_total_cols = (max_col + 1) * TILE_EFFECTIVE_SIZE

    # åˆå§‹åŒ–å®Œæ•´çš„é¢„æµ‹ç»“æœæ•°ç»„
    full_prediction_map = np.zeros((new_total_rows, new_total_cols), dtype=np.int8)

    print(f"âœ… æ‰¾åˆ° {total_tiles} ä¸ªåˆ‡ç‰‡ã€‚æœ€ç»ˆé¢„æµ‹å›¾å°ºå¯¸å°†è°ƒæ•´ä¸º {new_total_rows}x{new_total_cols}ã€‚")
    print(f"ğŸš€ å°†ä½¿ç”¨ BATCH_SIZE={BATCH_SIZE} è¿›è¡Œé¢„æµ‹ï¼Œå¹¶è£å‰ª {CROP_PIXELS} åƒç´ è¾¹ç¼˜ä»¥æ¶ˆé™¤æ¥ç¼...")

    # 2. æ‰¹å¤„ç†é¢„æµ‹å’Œå¡«å……

    file_metadata.sort(key=lambda x: (x['r'], x['c']))

    current_idx = 0

    with tqdm(total=total_tiles, desc="é¢„æµ‹åˆ‡ç‰‡è¿›åº¦") as pbar:
        while current_idx < total_tiles:
            batch_end = min(current_idx + BATCH_SIZE, total_tiles)
            batch_metadata = file_metadata[current_idx:batch_end]
            batch_size_actual = len(batch_metadata)

            batch_im1 = np.zeros((batch_size_actual, IMG_HEIGHT, IMG_WIDTH, NUM_BANDS), dtype=np.float32)
            batch_im2 = np.zeros((batch_size_actual, IMG_HEIGHT, IMG_WIDTH, NUM_BANDS), dtype=np.float32)

            for i, meta in enumerate(batch_metadata):
                path_t1 = os.path.join(IM1_DIR, meta['id'])
                path_t2 = os.path.join(IM2_DIR, meta['id'])

                if not os.path.exists(path_t2): continue

                im1, im2 = load_and_preprocess_tile(path_t1, path_t2)

                batch_im1[i] = im1
                batch_im2[i] = im2

            prediction_raw = model.predict([batch_im1, batch_im2], verbose=0)

            # å°†é¢„æµ‹ç»“æœè§£åŒ…å¹¶å¡«å……åˆ°å¤§å›¾ä¸­
            for i, pred_tile_raw in enumerate(prediction_raw):
                meta = batch_metadata[i]

                pred_tile = np.argmax(pred_tile_raw, axis=-1).astype(np.int8)

                # --- æ ¸å¿ƒä¿®æ”¹ï¼šè£å‰ªé¢„æµ‹ç»“æœä»¥æ¶ˆé™¤æ¥ç¼ ---
                pred_tile_cropped = pred_tile[
                                    CROP_PIXELS: IMG_HEIGHT - CROP_PIXELS,
                                    CROP_PIXELS: IMG_WIDTH - CROP_PIXELS
                                    ]
                # ----------------------------------------

                # è®¡ç®—åœ¨æœ€ç»ˆå›¾ä¸­çš„èµ·å§‹å’Œç»“æŸåæ ‡ï¼Œä½¿ç”¨æœ‰æ•ˆå°ºå¯¸ (TILE_EFFECTIVE_SIZE)
                start_row = meta['r'] * TILE_EFFECTIVE_SIZE
                end_row = start_row + TILE_EFFECTIVE_SIZE
                start_col = meta['c'] * TILE_EFFECTIVE_SIZE
                end_col = start_col + TILE_EFFECTIVE_SIZE

                # ç²˜è´´è£å‰ªåçš„ç»“æœ
                full_prediction_map[start_row:end_row, start_col:end_col] = pred_tile_cropped

            pbar.update(batch_size_actual)
            current_idx = batch_end

    # 3. å¯è§†åŒ–å®Œæ•´çš„å˜åŒ–å›¾

    # å®šä¹‰é¢œè‰²æ˜ å°„ (ä¸ä¹‹å‰ç›¸åŒ)
    colors = ['lightgray', 'blue', 'red', '#FFFFF7']
    cmap = ListedColormap(colors)
    bounds = [-0.5, 0.5, 1.5, 2.5, 3.5]
    norm = BoundaryNorm(bounds, cmap.N)

    # ä¿®å¤ Matplotlib é”™è¯¯ï¼šä½¿ç”¨ plt.subplots()
    fig, ax = plt.subplots(figsize=(10, 10))

    # ç»˜åˆ¶å›¾åƒåˆ° Axes å¯¹è±¡ä¸Š
    im = ax.imshow(full_prediction_map, cmap=cmap, norm=norm)

    ax.set_title("å®Œæ•´çš„å˜åŒ–ç›‘æµ‹é¢„æµ‹ç»“æœ(æ²³å—å¿)")
    ax.axis('off')

    # ä¿®æ­£ï¼šå°† im å’Œ ax ä¼ é€’ç»™ colorbar
    cbar = fig.colorbar(im, ax=ax, ticks=[0, 1, 2, 3])

    cbar.set_ticklabels(['0: æœªå˜åŒ– (ç°)', '1: æ´ªæ¶é£é™© (è“)', '2: è‰ç”¸ç ´å (çº¢)', '3: å…¶ä»–å˜åŒ– (é»„)'])

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    if not os.path.exists(SECOND_DATA_ROOT):
        os.makedirs(SECOND_DATA_ROOT)

    output_filename = os.path.join(SECOND_DATA_ROOT, 'full_change_map_cropped.png')
    plt.savefig(output_filename, bbox_inches='tight', dpi=300)
    print(f"\nğŸ‰ å®Œæ•´çš„å˜åŒ–ç›‘æµ‹å›¾å·²ä¿å­˜åˆ°: {output_filename}")

    plt.show()


# --- 5. ä¸»æ‰§è¡Œé€»è¾‘ ---

if __name__ == '__main__':
    loaded_model = load_best_model()
    if loaded_model:
        predict_and_stitch_full_image(loaded_model)